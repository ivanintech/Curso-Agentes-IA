{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3oSr9mjqUFp"
      },
      "source": [
        "<!-- NOTEBOOK_METADATA source: \"⚠️ Jupyter Notebook\" title: \"Trace the OpenAI Agents SDK with Langfuse\" sidebarTitle: \"OpenAI Agents\" logo: \"/images/integrations/openai_icon.svg\" description: \"Learn how to use Langfuse to monitor OpenAI Agents SDK to debug and evaluate your AI agents\" category: \"Integrations\" -->\n",
        "\n",
        "# Trace the OpenAI Agents SDK with Langfuse\n",
        "\n",
        "This notebook demonstrates how to **integrate Langfuse** into your **OpenAI Agents** workflow to monitor, debug and evaluate your AI agents.\n",
        "\n",
        "> **What is the OpenAI Agents SDK?**: The [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/) is a lightweight, open-source framework that lets developers build AI agents and orchestrate multi-agent workflows. It provides building blocks—such as tools, handoffs, and guardrails to configure large language models with custom instructions and integrated tools. Its Python-first design supports dynamic instructions and function tools for rapid prototyping and integration with external systems.\n",
        "\n",
        "> **What is Langfuse?**: [Langfuse](https://langfuse.com/) is an open-source observability platform for AI agents. It helps you visualize and monitor LLM calls, tool usage, cost, latency, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6viv5c1qUFr"
      },
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "Below we install the `openai-agents` library (the OpenAI Agents SDK), and the `pydantic-ai[logfire]` OpenTelemetry instrumentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XJLY1GqqUFr",
        "outputId": "fc3f1971-3c70-4d46-ed04-21da97d02563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-agents in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.1)\n",
            "Collecting langfuse\n",
            "  Downloading langfuse-3.10.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: nest_asyncio in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.0)\n",
            "Collecting pydantic-ai[logfire]\n",
            "  Downloading pydantic_ai-1.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (1.15.0)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (1.22.0)\n",
            "Requirement already satisfied: openai<3,>=2.8.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (2.8.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.12.3 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (2.12.5)\n",
            "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (2.31.0)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (2.32.4.20250913)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai-agents) (4.15.0)\n",
            "Requirement already satisfied: colorama>=0.4 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
            "Requirement already satisfied: anyio>=4.5 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.11.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.3)\n",
            "Requirement already satisfied: httpx>=0.27.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: pywin32>=310 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (311)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.50.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.38.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<3,>=2.8.0->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<3,>=2.8.0->openai-agents) (0.11.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<3,>=2.8.0->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<3,>=2.8.0->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio>=4.5->mcp<2,>=1.11.0->openai-agents) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=2.12.3->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=2.12.3->openai-agents) (2.41.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.0->openai-agents) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.0->openai-agents) (2.2.1)\n",
            "Collecting backoff>=1.10.0 (from langfuse)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 (from langfuse)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<26.0,>=23.2 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langfuse) (24.0)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langfuse) (1.16.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.19.2)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse)\n",
            "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pydantic-ai-slim==1.25.1 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading pydantic_ai_slim-1.25.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting genai-prices>=0.0.40 (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading genai_prices-0.0.47-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pydantic-graph==1.25.1 (from pydantic-ai-slim==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading pydantic_graph-1.25.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ag-ui-protocol>=0.1.8 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading ag_ui_protocol-0.1.10-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting anthropic>=0.75.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading anthropic-0.75.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting boto3>=1.40.14 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading boto3-1.42.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: prompt-toolkit>=3 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (3.0.52)\n",
            "Collecting pyperclip>=1.9.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached pyperclip-1.11.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting rich>=13 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cohere>=5.18.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading cohere-5.20.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pydantic-evals==1.25.1 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading pydantic_evals-1.25.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting fastmcp>=2.12.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading fastmcp-2.13.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting google-genai>=1.51.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading google_genai-1.52.0-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting groq>=0.25.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading groq-0.37.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.5 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (0.36.0)\n",
            "Collecting logfire>=3.14.1 (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading logfire-4.15.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting mistralai>=1.9.10 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting tenacity>=8.2.3 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting temporalio==1.19.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading temporalio-1.19.0-cp310-abi3-win_amd64.whl.metadata (94 kB)\n",
            "Collecting google-auth>=2.36.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting requests<3,>=2.0 (from openai-agents)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting logfire-api>=3.14.1 (from pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading logfire_api-4.15.1-py3-none-any.whl.metadata (972 bytes)\n",
            "Collecting pyyaml>=6.0.2 (from pydantic-evals==1.25.1->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
            "Collecting nexus-rpc==1.1.0 (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading nexus_rpc-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting types-protobuf>=3.20 (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading types_protobuf-6.32.1.20251105-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2025.10.0)\n",
            "Collecting aiohttp (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading aiohttp-3.13.2-cp311-cp311-win_amd64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (0.17.0)\n",
            "Collecting botocore<1.42.0,>=1.41.6 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading botocore-1.41.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botocore<1.42.0,>=1.41.6->boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.42.0,>=1.41.6->boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (1.16.0)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading fastavro-1.12.1-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.11.0->openai-agents)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (0.22.1)\n",
            "Collecting authlib>=1.6.5 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached authlib-1.6.5-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting cyclopts>=4.0.0 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached cyclopts-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting jsonschema-path>=0.3.4 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (4.5.0)\n",
            "Collecting py-key-value-aio<0.4.0,>=0.2.8 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading py_key_value_aio-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.1.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (1.2.1)\n",
            "Collecting websockets>=15.0.1 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting py-key-value-shared==0.3.0 (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading py_key_value_shared-0.3.0-py3-none-any.whl.metadata (706 bytes)\n",
            "Collecting beartype>=0.20.0 (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading beartype-0.22.7-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting diskcache>=5.0.0 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pathvalidate>=3.3.1 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: cachetools>=5.0.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (5.3.3)\n",
            "Requirement already satisfied: cryptography in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (46.0.3)\n",
            "Requirement already satisfied: attrs>=23.1.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (25.4.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached rich_rst-1.3.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting docutils (from rich-rst<2.0.0,>=1.3.1->cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached docutils-0.22.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.30.0)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path>=0.3.4->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: executing>=2.0.1 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2.2.1)\n",
            "Collecting opentelemetry-instrumentation>=0.41b0 (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opentelemetry-instrumentation-httpx>=0.42b0 (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading opentelemetry_instrumentation_httpx-0.59b0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading eval_type_backport-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting opentelemetry-util-http==0.59b0 (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (0.2.14)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cryptography->authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=2.0.0->cryptography->authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2.23)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire]) (2.19.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\ivanc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.1.7)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.25.1->pydantic-ai[logfire])\n",
            "  Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl.metadata (77 kB)\n",
            "Downloading langfuse-3.10.3-py3-none-any.whl (399 kB)\n",
            "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
            "Downloading pydantic_ai-1.25.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading pydantic_ai_slim-1.25.1-py3-none-any.whl (422 kB)\n",
            "Downloading pydantic_evals-1.25.1-py3-none-any.whl (56 kB)\n",
            "Downloading pydantic_graph-1.25.1-py3-none-any.whl (72 kB)\n",
            "Downloading temporalio-1.19.0-cp310-abi3-win_amd64.whl (14.3 MB)\n",
            "   ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 1.0/14.3 MB 6.3 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 3.4/14.3 MB 9.2 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 7.6/14.3 MB 13.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.3/14.3 MB 18.7 MB/s  0:00:00\n",
            "Downloading nexus_rpc-1.1.0-py3-none-any.whl (27 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading ag_ui_protocol-0.1.10-py3-none-any.whl (7.9 kB)\n",
            "Downloading anthropic-0.75.0-py3-none-any.whl (388 kB)\n",
            "Downloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading boto3-1.42.0-py3-none-any.whl (140 kB)\n",
            "Downloading botocore-1.41.6-py3-none-any.whl (14.4 MB)\n",
            "   ---------------------------------------- 0.0/14.4 MB ? eta -:--:--\n",
            "   -------------------------- ------------- 9.4/14.4 MB 45.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.4/14.4 MB 41.2 MB/s  0:00:00\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "Downloading cohere-5.20.0-py3-none-any.whl (303 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.12.1-cp311-cp311-win_amd64.whl (450 kB)\n",
            "Downloading fastmcp-2.13.2-py3-none-any.whl (385 kB)\n",
            "Downloading py_key_value_aio-0.3.0-py3-none-any.whl (96 kB)\n",
            "Downloading py_key_value_shared-0.3.0-py3-none-any.whl (19 kB)\n",
            "Using cached authlib-1.6.5-py2.py3-none-any.whl (243 kB)\n",
            "Downloading beartype-0.22.7-py3-none-any.whl (1.3 MB)\n",
            "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.3/1.3 MB 17.0 MB/s  0:00:00\n",
            "Using cached cyclopts-4.3.0-py3-none-any.whl (187 kB)\n",
            "Using cached rich_rst-1.3.2-py3-none-any.whl (12 kB)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Using cached exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
            "Downloading genai_prices-0.0.47-py3-none-any.whl (57 kB)\n",
            "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading google_genai-1.52.0-py3-none-any.whl (261 kB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "Downloading groq-0.37.0-py3-none-any.whl (137 kB)\n",
            "Using cached jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Using cached pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading logfire-4.15.1-py3-none-any.whl (228 kB)\n",
            "Downloading logfire_api-4.15.1-py3-none-any.whl (95 kB)\n",
            "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
            "Downloading eval_type_backport-0.3.0-py3-none-any.whl (6.1 kB)\n",
            "Using cached openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_instrumentation_httpx-0.59b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_util_http-0.59b0-py3-none-any.whl (7.6 kB)\n",
            "Using cached pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "Using cached pyperclip-1.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading types_protobuf-6.32.1.20251105-py3-none-any.whl (77 kB)\n",
            "Downloading aiohttp-3.13.2-cp311-cp311-win_amd64.whl (456 kB)\n",
            "Downloading multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
            "Downloading yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
            "Downloading propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
            "Using cached docutils-0.22.3-py3-none-any.whl (633 kB)\n",
            "Installing collected packages: pyperclip, websockets, types-protobuf, tenacity, requests, referencing, pyyaml, pyasn1, protobuf, propcache, pathvalidate, pathable, opentelemetry-util-http, nexus-rpc, multidict, mdurl, logfire-api, jmespath, invoke, httpx-sse, frozenlist, fastavro, exceptiongroup, eval-type-backport, docutils, dnspython, diskcache, beartype, backoff, argcomplete, aiohappyeyeballs, yarl, temporalio, rsa, pyasn1-modules, py-key-value-shared, opentelemetry-proto, opentelemetry-api, markdown-it-py, jsonschema-path, googleapis-common-protos, email-validator, botocore, aiosignal, s3transfer, rich, pydantic-graph, py-key-value-aio, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, openapi-pydantic, mistralai, groq, google-auth, genai-prices, authlib, anthropic, aiohttp, ag-ui-protocol, rich-rst, pydantic-ai-slim, opentelemetry-sdk, opentelemetry-instrumentation, google-genai, cohere, boto3, pydantic-evals, opentelemetry-instrumentation-httpx, opentelemetry-exporter-otlp-proto-http, cyclopts, logfire, langfuse, fastmcp, pydantic-ai\n",
            "\n",
            "    ---------------------------------------  1/74 [websockets]\n",
            "  Attempting uninstall: requests\n",
            "    ---------------------------------------  1/74 [websockets]\n",
            "    Found existing installation: requests 2.31.0\n",
            "    ---------------------------------------  1/74 [websockets]\n",
            "    Uninstalling requests-2.31.0:\n",
            "    ---------------------------------------  1/74 [websockets]\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "    ---------------------------------------  1/74 [websockets]\n",
            "   -- -------------------------------------  4/74 [requests]\n",
            "  Attempting uninstall: referencing\n",
            "   -- -------------------------------------  4/74 [requests]\n",
            "    Found existing installation: referencing 0.37.0\n",
            "   -- -------------------------------------  4/74 [requests]\n",
            "    Uninstalling referencing-0.37.0:\n",
            "   -- -------------------------------------  4/74 [requests]\n",
            "      Successfully uninstalled referencing-0.37.0\n",
            "   -- -------------------------------------  4/74 [requests]\n",
            "   -- -------------------------------------  5/74 [referencing]\n",
            "  Attempting uninstall: pyyaml\n",
            "   -- -------------------------------------  5/74 [referencing]\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "   -- -------------------------------------  5/74 [referencing]\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "   -- -------------------------------------  5/74 [referencing]\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "   -- -------------------------------------  5/74 [referencing]\n",
            "   --- ------------------------------------  7/74 [pyasn1]\n",
            "  Attempting uninstall: protobuf\n",
            "   --- ------------------------------------  7/74 [pyasn1]\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "   --- ------------------------------------  7/74 [pyasn1]\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "   --- ------------------------------------  7/74 [pyasn1]\n",
            "   ---- -----------------------------------  8/74 [protobuf]\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "   ---- -----------------------------------  8/74 [protobuf]\n",
            "   ---- -----------------------------------  8/74 [protobuf]\n",
            "   ---- -----------------------------------  8/74 [protobuf]\n",
            "   ------- -------------------------------- 13/74 [nexus-rpc]\n",
            "   -------- ------------------------------- 16/74 [logfire-api]\n",
            "   --------- ------------------------------ 18/74 [invoke]\n",
            "  Attempting uninstall: httpx-sse\n",
            "   --------- ------------------------------ 18/74 [invoke]\n",
            "    Found existing installation: httpx-sse 0.4.3\n",
            "   --------- ------------------------------ 18/74 [invoke]\n",
            "    Uninstalling httpx-sse-0.4.3:\n",
            "   --------- ------------------------------ 18/74 [invoke]\n",
            "      Successfully uninstalled httpx-sse-0.4.3\n",
            "   --------- ------------------------------ 18/74 [invoke]\n",
            "   ----------- ---------------------------- 21/74 [fastavro]\n",
            "   ------------ --------------------------- 24/74 [docutils]\n",
            "   ------------ --------------------------- 24/74 [docutils]\n",
            "   ------------ --------------------------- 24/74 [docutils]\n",
            "   ------------ --------------------------- 24/74 [docutils]\n",
            "   ------------- -------------------------- 25/74 [dnspython]\n",
            "   ------------- -------------------------- 25/74 [dnspython]\n",
            "   ------------- -------------------------- 25/74 [dnspython]\n",
            "   ------------- -------------------------- 25/74 [dnspython]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   -------------- ------------------------- 27/74 [beartype]\n",
            "   --------------- ------------------------ 29/74 [argcomplete]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ----------------- ---------------------- 32/74 [temporalio]\n",
            "   ------------------ --------------------- 34/74 [pyasn1-modules]\n",
            "   ------------------ --------------------- 34/74 [pyasn1-modules]\n",
            "   ------------------ --------------------- 34/74 [pyasn1-modules]\n",
            "   ------------------- -------------------- 36/74 [opentelemetry-proto]\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "   ------------------- -------------------- 36/74 [opentelemetry-proto]\n",
            "    Found existing installation: opentelemetry-api 1.25.0\n",
            "   ------------------- -------------------- 36/74 [opentelemetry-proto]\n",
            "    Uninstalling opentelemetry-api-1.25.0:\n",
            "   ------------------- -------------------- 36/74 [opentelemetry-proto]\n",
            "      Successfully uninstalled opentelemetry-api-1.25.0\n",
            "   ------------------- -------------------- 36/74 [opentelemetry-proto]\n",
            "   -------------------- ------------------- 37/74 [opentelemetry-api]\n",
            "   -------------------- ------------------- 38/74 [markdown-it-py]\n",
            "   --------------------- ------------------ 39/74 [jsonschema-path]\n",
            "   --------------------- ------------------ 40/74 [googleapis-common-protos]\n",
            "   ---------------------- ----------------- 41/74 [email-validator]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ---------------------- ----------------- 42/74 [botocore]\n",
            "   ----------------------- ---------------- 44/74 [s3transfer]\n",
            "   ------------------------ --------------- 45/74 [rich]\n",
            "   ------------------------ --------------- 45/74 [rich]\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.46b0\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.46b0:\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.46b0\n",
            "   ------------------------- -------------- 47/74 [py-key-value-aio]\n",
            "   --------------------- ----------- 48/74 [opentelemetry-semantic-conventions]\n",
            "   --------------------- ----------- 48/74 [opentelemetry-semantic-conventions]\n",
            "   --------------------------- ------------ 50/74 [openapi-pydantic]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   --------------------------- ------------ 51/74 [mistralai]\n",
            "   ---------------------------- ----------- 52/74 [groq]\n",
            "   ---------------------------- ----------- 52/74 [groq]\n",
            "   ---------------------------- ----------- 53/74 [google-auth]\n",
            "   ----------------------------- ---------- 54/74 [genai-prices]\n",
            "   ----------------------------- ---------- 55/74 [authlib]\n",
            "   ----------------------------- ---------- 55/74 [authlib]\n",
            "   ----------------------------- ---------- 55/74 [authlib]\n",
            "  Attempting uninstall: anthropic\n",
            "   ----------------------------- ---------- 55/74 [authlib]\n",
            "    Found existing installation: anthropic 0.72.0\n",
            "   ----------------------------- ---------- 55/74 [authlib]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "    Uninstalling anthropic-0.72.0:\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "      Successfully uninstalled anthropic-0.72.0\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 56/74 [anthropic]\n",
            "   ------------------------------ --------- 57/74 [aiohttp]\n",
            "   ------------------------------- -------- 59/74 [rich-rst]\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "    Found existing installation: opentelemetry-sdk 1.25.0\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "    Uninstalling opentelemetry-sdk-1.25.0:\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "      Successfully uninstalled opentelemetry-sdk-1.25.0\n",
            "   -------------------------------- ------- 60/74 [pydantic-ai-slim]\n",
            "   -------------------------------- ------- 61/74 [opentelemetry-sdk]\n",
            "   ------------------------------- ------ 62/74 [opentelemetry-instrumentation]\n",
            "   ---------------------------------- ----- 63/74 [google-genai]\n",
            "   ---------------------------------- ----- 64/74 [cohere]\n",
            "   ---------------------------------- ----- 64/74 [cohere]\n",
            "   ---------------------------------- ----- 64/74 [cohere]\n",
            "   ---------------------------------- ----- 64/74 [cohere]\n",
            "   ---------------------------------- ----- 64/74 [cohere]\n",
            "   ----------------------------------- ---- 65/74 [boto3]\n",
            "   ----------------------------------- ---- 66/74 [pydantic-evals]\n",
            "   ------------------------------------- -- 69/74 [cyclopts]\n",
            "   ------------------------------------- -- 69/74 [cyclopts]\n",
            "   ------------------------------------- -- 70/74 [logfire]\n",
            "   ------------------------------------- -- 70/74 [logfire]\n",
            "   -------------------------------------- - 71/74 [langfuse]\n",
            "   -------------------------------------- - 71/74 [langfuse]\n",
            "   -------------------------------------- - 71/74 [langfuse]\n",
            "   -------------------------------------- - 71/74 [langfuse]\n",
            "   -------------------------------------- - 71/74 [langfuse]\n",
            "   -------------------------------------- - 72/74 [fastmcp]\n",
            "   -------------------------------------- - 72/74 [fastmcp]\n",
            "   -------------------------------------- - 72/74 [fastmcp]\n",
            "   ---------------------------------------- 74/74 [pydantic-ai]\n",
            "\n",
            "Successfully installed ag-ui-protocol-0.1.10 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anthropic-0.75.0 argcomplete-3.6.3 authlib-1.6.5 backoff-2.2.1 beartype-0.22.7 boto3-1.42.0 botocore-1.41.6 cohere-5.20.0 cyclopts-4.3.0 diskcache-5.6.3 dnspython-2.8.0 docutils-0.22.3 email-validator-2.3.0 eval-type-backport-0.3.0 exceptiongroup-1.3.1 fastavro-1.12.1 fastmcp-2.13.2 frozenlist-1.8.0 genai-prices-0.0.47 google-auth-2.43.0 google-genai-1.52.0 googleapis-common-protos-1.72.0 groq-0.37.0 httpx-sse-0.4.0 invoke-2.2.1 jmespath-1.0.1 jsonschema-path-0.3.4 langfuse-3.10.3 logfire-4.15.1 logfire-api-4.15.1 markdown-it-py-4.0.0 mdurl-0.1.2 mistralai-1.9.11 multidict-6.7.0 nexus-rpc-1.1.0 openapi-pydantic-0.5.1 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-httpx-0.59b0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opentelemetry-util-http-0.59b0 pathable-0.4.4 pathvalidate-3.3.1 propcache-0.4.1 protobuf-6.33.1 py-key-value-aio-0.3.0 py-key-value-shared-0.3.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-ai-1.25.1 pydantic-ai-slim-1.25.1 pydantic-evals-1.25.1 pydantic-graph-1.25.1 pyperclip-1.11.0 pyyaml-6.0.3 referencing-0.36.2 requests-2.32.5 rich-14.2.0 rich-rst-1.3.2 rsa-4.9.1 s3transfer-0.16.0 temporalio-1.19.0 tenacity-9.1.2 types-protobuf-6.32.1.20251105 websockets-15.0.1 yarl-1.22.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: pydantic-ai 1.25.1 does not provide the extra 'logfire'\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlflow 2.13.2 requires protobuf<5,>=3.12.0, but you have protobuf 6.33.1 which is incompatible.\n",
            "mlflow 2.13.2 requires pyarrow<16,>=4.0.0, but you have pyarrow 22.0.0 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai-agents langfuse nest_asyncio \"pydantic-ai[logfire]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnixf7bZqUFr"
      },
      "source": [
        "## 2. Configure Environment & Langfuse Credentials\n",
        "\n",
        "Next, set up your Langfuse API keys. You can get these keys by signing up for a free [Langfuse Cloud](https://cloud.langfuse.com/) account or by [self-hosting Langfuse](https://langfuse.com/self-hosting). These environment variables are essential for the Langfuse client to authenticate and send data to your Langfuse project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp4-f-o9qUFr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Configuración de Nebius AI completada\n",
            "✅ Modelo: meta-llama/Llama-3.3-70B-Instruct\n",
            "✅ Langfuse Host: https://cloud.langfuse.com\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import base64\n",
        "\n",
        "\n",
        "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # 🇪🇺 EU region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # 🇺🇸 US region\n",
        "\n",
        "# Build Basic Auth header.\n",
        "#LANGFUSE_AUTH = base64.b64encode(\n",
        "#    f\"{os.environ.get('LANGFUSE_PUBLIC_KEY')}:{os.environ.get('LANGFUSE_SECRET_KEY')}\".encode()\n",
        "#).decode()\n",
        "\n",
        "# Configure OpenTelemetry endpoint & headers\n",
        "#os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = os.environ.get(\"LANGFUSE_HOST\") + \"/api/public/otel\"\n",
        "#os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "\n",
        "\n",
        "# Your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM-tCggDqUFs"
      },
      "source": [
        "## 3. Instrumenting the Agent\n",
        "\n",
        "Pydantic Logfire offers an instrumentation for the OpenAi Agent SDK. We use this to send traces to Langfuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hwl40YG_qUFs"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AHgVsmGzqUFs"
      },
      "outputs": [],
      "source": [
        "import logfire\n",
        "\n",
        "# Configure logfire instrumentation.\n",
        "logfire.configure(\n",
        "    service_name='my_agent_service',\n",
        "    send_to_logfire=False,\n",
        ")\n",
        "# This method automatically patches the OpenAI Agents SDK to send logs via OTLP to Langfuse.\n",
        "logfire.instrument_openai_agents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4BcWJ8yqUFs"
      },
      "source": [
        "Now initialize the Langfuse client. `get_client()` initializes the Langfuse client using the credentials provided in the environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ55t_txqUFs",
        "outputId": "867df123-fb3a-4a3b-ce9e-7d4270dcf6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Langfuse client is authenticated and ready!\n"
          ]
        }
      ],
      "source": [
        "from langfuse import get_client\n",
        "\n",
        "langfuse = get_client()\n",
        "\n",
        "# Verify connection\n",
        "if langfuse.auth_check():\n",
        "    print(\"Langfuse client is authenticated and ready!\")\n",
        "else:\n",
        "    print(\"Authentication failed. Please check your credentials and host.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOX4EMWpqUFs"
      },
      "source": [
        "## 4. Hello World Example\n",
        "\n",
        "Below we create an **OpenAI Agent** that always replies in **haiku** form. We run it with `Runner.run` and print the final output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CX079cfqUFs",
        "outputId": "bae4fba7-f394-48ed-9736-38b58f11aaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:43:53.168 OpenAI Agents trace: Agent workflow\n",
            "12:43:53.172   Agent run: 'Assistant'\n",
            "12:43:53.174     Chat completion with 'meta-llama/Llama-3.3-70B-Instruct' [LLM]\n",
            "Functions call self\n",
            "Echoes of code repeat deep\n",
            "Solving with each step\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=\"gpt-4.1-mini\"\n",
        "    )\n",
        "\n",
        "    result = await Runner.run(agent, \"Tell me about recursion in programming.\")\n",
        "    print(result.final_output)\n",
        "\n",
        "loop = asyncio.get_running_loop()\n",
        "await loop.create_task(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zfjllnvvy7a4"
      },
      "outputs": [],
      "source": [
        "# langfuse.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4omTxsYeqUFs"
      },
      "source": [
        "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_openai-agents/openai-agent-example-trace.png)\n",
        "\n",
        "**Example**: [Langfuse Trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/019593c7330da67c08219bd1c75b7a6d?timestamp=2025-03-14T08%3A31%3A00.365Z&observation=81e525d819153eed)\n",
        "\n",
        "Clicking the link above (or your own project link) lets you view all sub-spans, token usage, latencies, etc., for debugging or optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Pf9VRhqUFs"
      },
      "source": [
        "## 5. Multi-agent Handoff Example\n",
        "\n",
        "Here we create:\n",
        "- A **Spanish agent** that responds only in Spanish.\n",
        "- An **English agent** that responds only in English.\n",
        "- A **Triage agent** that routes the request to the correct agent based on the input language.\n",
        "\n",
        "Any calls or handoffs are captured as part of the trace. That way, you can see which sub-agent or tool was used, as well as the final result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuI8c0gCqUFs",
        "outputId": "e6d5f559-5c93-437f-d917-30d95b3a0c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:43:54.680 OpenAI Agents trace: Agent workflow\n",
            "12:43:54.680   Agent run: 'Triage agent'\n",
            "12:43:54.681     Chat completion with 'meta-llama/Llama-3.3-70B-Instruct' [LLM]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[non-fatal] Tracing client error 401: {\n",
            "  \"error\": {\n",
            "    \"message\": \"Your authentication token is not from a valid issuer.\",\n",
            "    \"type\": \"invalid_request_error\",\n",
            "    \"param\": null,\n",
            "    \"code\": \"invalid_issuer\"\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:43:55.890     Handoff: Triage agent → None\n",
            "12:43:55.891   Agent run: 'Spanish agent'\n",
            "12:43:55.892     Chat completion with 'meta-llama/Llama-3.3-70B-Instruct' [LLM]\n",
            "¡Hola! ¿En qué puedo ayudarte hoy?\n"
          ]
        }
      ],
      "source": [
        "from agents import Agent, Runner\n",
        "import asyncio\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish agent\",\n",
        "    instructions=\"You only speak Spanish.\",\n",
        "     model=\"gpt-4.1-mini\",\n",
        ")\n",
        "\n",
        "english_agent = Agent(\n",
        "    name=\"English agent\",\n",
        "    instructions=\"You only speak English\",\n",
        "    model=\"gpt-4.1-mini\",\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage agent\",\n",
        "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
        "    handoffs=[spanish_agent, english_agent],\n",
        "    model=\"gpt-4.1-mini\"\n",
        ")\n",
        "\n",
        "result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n",
        "print(result.final_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKCus30VqUFs"
      },
      "source": [
        "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_openai-agents/openai-agent-example-trace-handoff.png)\n",
        "\n",
        "**Example**: [Langfuse Trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/019593c74429a6d0489e9259703a1148?timestamp=2025-03-14T08%3A31%3A04.745Z&observation=e83609282c443b0d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy85SMriqUFt"
      },
      "source": [
        "## 6. Functions Example\n",
        "\n",
        "The OpenAI Agents SDK allows the agent to call Python functions. With Langfuse instrumentation, you can see which **functions** are called, their arguments, and the return values. Here we define a simple function `get_weather(city: str)` and add it as a tool.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlI1-kMNqUFt",
        "outputId": "93263353-b6c2-4234-f8be-a3c77e822f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:43:56.507 OpenAI Agents trace: Agent workflow\n",
            "12:43:56.508   Agent run: 'Hello world'\n",
            "12:43:56.509     Chat completion with 'meta-llama/Llama-3.3-70B-Instruct' [LLM]\n",
            "12:43:57.483     Function: get_weather\n",
            "12:43:57.485     Chat completion with 'meta-llama/Llama-3.3-70B-Instruct' [LLM]\n",
            "I am not able to execute this request. Please try something else.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[non-fatal] Tracing client error 401: {\n",
            "  \"error\": {\n",
            "    \"message\": \"Your authentication token is not from a valid issuer.\",\n",
            "    \"type\": \"invalid_request_error\",\n",
            "    \"param\": null,\n",
            "    \"code\": \"invalid_issuer\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner, function_tool\n",
        "\n",
        "# Example function tool.\n",
        "@function_tool\n",
        "def get_weather(city: str) -> str:\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Hello world\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    tools=[get_weather],\n",
        ")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
        "    print(result.final_output)\n",
        "\n",
        "loop = asyncio.get_running_loop()\n",
        "await loop.create_task(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84TWOSFVqUFt"
      },
      "source": [
        "![Example trace in Langfuse](https://langfuse.com/images/cookbook/integration_openai-agents/openai-agent-example-trace-function.png)\n",
        "\n",
        "**Example**: [Langfuse Trace](https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/019593c74a162f93387d9261b01f9ca9?timestamp=2025-03-14T08%3A31%3A06.262Z&observation=0e2988966786cdf4)\n",
        "\n",
        "When viewing the trace, you’ll see a span capturing the function call `get_weather` and the arguments passed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuqLBgSMqUFt"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [Example notebook on evaluating agents](https://langfuse.com/guides/cookbook/example_evaluating_openai_agents) with Langfuse.\n",
        "\n",
        "<!-- MARKDOWN_COMPONENT name: \"LearnMore\" path: \"@/components-mdx/integration-learn-more.mdx\" -->"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
